---
title: '[IML] Topics 1 - 6'
---

# Introduction to Machine Learning (Topics 1 - 6)

## 1. Tests for Artificial General Intelligence

### Turing Test

The Turing Test, proposed by Alan Turing in 1950, is a method to assess whether a machine exhibits human-like intelligence. The test involves a human evaluator who converses with both a machine and a human, without knowing which is which. If the evaluator cannot reliably distinguish the machine from the human, and is fooled a significant fraction of the time, the machine is considered to have passed the test. Turing intentionally avoided defining intelligence, arguing instead that indistinguishability from a human should be the primary criterion. A notable milestone in this area occurred in 2014 when an AI named Eugene Goostman convinced 30% of judges it was human—a threshold Turing estimated could indicate success.

#### Short points

- A machine and a human both converse unseen with a second human
- The second human must evaluate which of the two is the machine
- The test is passed if the evaluator is fooled a significant fraction of the time
- Turing does not prescribe what should qualify as intelligence, only that knowing that it is a machine should disqualify it.
- The AI Eugene Goostman achieved Turing's estimate of convincing 30% of judges that it was human in 2014

### Robot College Student Test (Goertzel)

The Robot College Student Test, proposed by Ben Goertzel, evaluates a machine's intelligence based on its ability to successfully complete a university degree. This involves enrolling in and passing the same courses as human students. Recent advancements in large language models (LLMs) have brought this test closer to reality, as some AI systems can pass degree-level exams without attending classes. While these systems excel in processing and generating knowledge, they are not yet autonomous agents capable of physically or socially navigating a university environment.

#### Short points

- A machine enrolls in a university, taking and passing the same classes that humans would, and obtaining a degree
- Some LLMs can now pass university degree-level exams without even attending the classes
- These systems are not yet autonomous agents capable of navigating a university environment

### Employment Test (Nilsson)

The Employment Test, suggested by Nils Nilsson, measures a machine's intelligence by its ability to perform economically significant jobs as effectively as humans. In practice, AI has already replaced humans in many roles, from customer service and fast food preparation to marketing and even some creative tasks. These AI systems, however, typically function within a narrow domain of expertise, making them examples of narrow AI rather than artificial general intelligence (AGI). While they excel in specific tasks, they lack the broad adaptability and reasoning capabilities that define AGI.

#### Short points

- A machine performs an economically important job at least as well as humans in the same job
- AIs are now replacing humans in many roles as varied as fast food, and marketing
- These AIs are examples of narrow AI, not AGI, as they are specialized to a narrow domain

### IKEA Test (Marcus)

The IKEA Test, also called the Flat Pack Furniture Test, was proposed by Gary Marcus as a measure of an AI's physical and cognitive coordination. It involves providing an AI with the parts and assembly instructions for an IKEA flat-pack product. The AI must then control a robotic system to correctly assemble the furniture. This test assesses the AI’s ability to interpret visual and textual information, plan a sequence of actions, and physically execute them with precision. Though robots have achieved some success in simpler tasks like screwing bolts or placing parts, assembling complex furniture remains a significant challenge for AI due to the intricate mix of spatial reasoning, dexterity, and problem-solving required.

#### Short points

- Also known as the Flat Pack Furniture Test
- An AI views the parts and instructions of an Ikea flat-pack product, then controls a robot to assemble the furniture correctly
- The test assesses the AI's ability to interpret visual and textual information, plan a sequence of actions, and execute

### Coffee Test (Wozniak)

The Coffee Test, proposed by Steve Wozniak, evaluates an AI's capability to autonomously interact with a typical human environment. The test requires an AI to enter an average home, identify and locate a coffee machine, find the coffee grounds and a mug, add water, and successfully brew a cup of coffee by operating the machine. This task, though seemingly simple, demands advanced perceptual and reasoning abilities, as well as adaptability to novel environments. To date, no AI has successfully passed this test, as it involves combining general knowledge, object recognition, spatial navigation, and physical interaction—all of which remain challenging for machines outside tightly controlled settings.

#### Short points

- A machine enters an average home and figures out how to make coffee:
  - Find the coffee machine
  - Locate the coffee grounds and a mug
  - Add water and brew a cup of coffee
- This has not yet been completed
- The test requires general knowledge, object recognition, spatial navigation, and physical interaction

## 2. Techniques for Generative AI

Generative AI focuses on creating new content, such as images, text, or music, by learning patterns from data. Key techniques include **Generative Adversarial Networks (GANs)**, **Autoencoders**, and **Variational Autoencoders (VAEs)**.

### Generative Adversarial Networks (GANs)

GANs consist of two neural networks: a generator and a discriminator, trained in a competitive setup. The generator creates synthetic data (e.g., images), while the discriminator evaluates whether the input is real or fake. This adversarial process improves the generator's output over time, leading to highly realistic results. GANs are widely used for generating images, videos, and even synthetic datasets. However, training GANs is challenging due to issues like training instability, mode collapse (producing limited diversity), and heavy computational demands.

::: tip
GANs are like a game between two players: the generator and the discriminator. The generator tries to create fake data (like images), and the discriminator tries to figure out if the data is fake or real. Over time, the generator gets better at tricking the discriminator, and the discriminator gets better at spotting fakes. This process helps the generator create very realistic images. However, training GANs is tricky because the two players can become unbalanced, or the generator might only create a limited variety of images (this is called mode collapse).
:::

#### Skeleton code for GANs

```python
# Initialize Generator (G) and Discriminator (D) networks
initializeGeneratorG()
initializeDiscriminatorD()
# Set learning rates and other hyperparameters
learning_rate_G = 0.001
learning_rate_D = 0.001
num_epochs = 10000

for epoch in range(num_epochs):

  # Step 1: Train Discriminator D
  for batch in real_data:     

    # Sample random noise (z) to create fake data
    z = random_noise()

    # Generate fake data using Generator G
    fake_data = G(z)

    # Get Discriminator's prediction on
    # real and fake data
    # should be close to 1 (real)
    real_prediction = D(real_data)
    # should be close to 0 (fake)
    fake_prediction = D(fake_data)

    # Calculate loss for Discriminator
    D_loss = -(log(real_prediction) + log(1 - fake_prediction))

    # Update Discriminator D's weights
    update_weights(D, D_loss, learning_rate_D)

  # Step 2: Train Generator G
  for batch in real_data:

    # Sample random noise (z)
    z = random_noise()

    # Generate fake data
    fake_data = G(z)
       
    # Get Discriminator's prediction on fake data
    # we want this to be close to 1
    fake_prediction = D(fake_data)      
       
    # Calculate loss for Generator
    G_loss = -log(fake_prediction)
       
    # Update Generator G's weights
    update_weights(G, G_loss, learning_rate_G)

# Print loss and progress every few epochs
if epoch % 100 == 0:
  print(f"Epoch {epoch}: D_loss = {D_loss}, G_loss = {G_loss}")
```

#### Key Points

- Two components: generator (creates data) and discriminator (evaluates data).
- Adversarial training improves data realism.
- Applications include StyleGAN (synthetic images) and creative content generation.
- Difficulties of GAN Training:
  - Training instability - discriminator or generator overpowering the other
  - Mode collapse - limited diversity in generated data
  - Non-Convergence - models not reaching a stable state
  - Vanishing Gradients - Generator receiving too little feedback if e.g. discriminator is too good
  - Sensitive to Hyperparameters - requires careful tuning
  - Lack of Evaluation Metrics - no clear way to measure quality
  - Heavy computational requirements - training can be slow and resource-intensive

### Autoencoders

Autoencoders are neural networks used for dimensionality reduction, anomaly detection, and feature extraction. They consist of two parts: an encoder, which compresses the input data into a latent representation, and a decoder, which reconstructs the input from this representation. Unlike VAEs, autoencoders are deterministic and focus on exact reconstruction, not probabilistic sampling. Autoencoders are less suited for generating entirely new data but excel in tasks like denoising, compressing, and reconstructing data.

::: tip
Autoencoders are like a tool for simplifying and recreating data. They have two parts: an encoder that shrinks the data into a smaller form (latent space) and a decoder that expands it back to the original. Unlike VAEs, autoencoders are not designed to create new data, just to recreate what they’ve seen. They are great for finding errors in data, cleaning up noisy images, or compressing information.
:::

![](/assets/intro-ml/encoder.png)

#### Autoencoder Components

- **Input**: $\mathbb{R}^D$

The data you give to the model starts in a very high-dimensional space. For example, if you're working with images, each pixel contributes to the "dimension" of the input space.

- **Output**: $\mathbb{R}^D$

The output of the autoencoder should be the same as the input. This means the model needs to learn how to compress and then reconstruct the data accurately.

- **Embedding**: $f: \mathbb{R}^D \rightarrow \mathbb{R}^d$

The encoder takes the high-dimensional input ($\mathbb{R}^D$) and maps it to a lower-dimensional space ($\mathbb{R}^d$). This lower-dimensional space is called the latent space, and it's where the data is compressed.

- **Decoding**: $g: \mathbb{R}^d \rightarrow \mathbb{R}^D$

The decoder takes the compressed data from the latent space and reconstructs it back to the original high-dimensional space. The goal is to make the output as close as possible to the input. Mathematically, it means that for each input $x$, the output $g(f(x))$ should be as close as possible to $x$.

- **Generative output**: $\quad g(y) \quad (y \in \mathbb{R}^d, \text{random})$

The really cool part: instead of encoding and decoding the original input, we can give random points ($y$) in the latent space ($\mathbb{R}^d$) to the decoder. This generates entirely new outputs that look like the original data but aren’t exact copies. For example, in an image application, this could create new images that look realistic but were never seen in the training data.

#### Key Points

- Two components: encoder (compresses data) and decoder (reconstructs data).
- Focused on reconstruction accuracy, not diversity.
- Applications: anomaly detection, data compression, and feature extraction.
- Simpler than VAEs but limited in generative applications.

### Variational Autoencoders (VAEs)

VAEs are a probabilistic extension of autoencoders, designed to generate new data by learning a latent representation. They encode input data into a continuous latent space, where each point represents a probability distribution instead of a fixed value. This makes VAEs ideal for sampling new, diverse data points. During training, VAEs minimize two losses: reconstruction loss (how well the output matches the input) and KL divergence (how close the latent distribution is to a standard Gaussian). VAEs are commonly used for generating images, text, and interpolating between samples.

::: tip
VAEs are special tools for creating new data, like images. They work by turning the input (e.g., an image) into a latent space, which is like a smaller, compressed version of the data. This latent space uses probabilities, meaning it can create new, slightly different images by sampling points within it. VAEs focus on two goals during training: making sure the output is close to the input (reconstruction) and keeping the latent space well-organized (KL divergence). This helps them create smooth and varied outputs.
:::

#### Key Points

- Encodes data into a probabilistic latent space.
- Balances two losses: reconstruction and KL divergence.
- Generates diverse, smooth outputs suitable for sampling.
- Applications: image generation, anomaly detection, and latent space exploration.

## 3. Text to image models

Text-to-image models generate images based on textual descriptions, combining natural language understanding with image synthesis. These models typically use techniques like diffusion models, transformers, and GANs. Diffusion models, for example, iteratively refine noisy images into high-quality visuals, guided by textual embeddings. A key example is DALL·E, which uses a transformer-based architecture to translate text prompts into vivid and coherent images. These systems leverage large-scale datasets to align language with visual elements, enabling high-quality results for diverse and complex prompts.

Despite advancements, challenges persist, such as ensuring accurate alignment between text and image content, avoiding biases in data, and generating high-resolution outputs efficiently. Text-to-image models also face ethical considerations, as they can inadvertently replicate biases or be misused for generating harmful content.

### Key Models

- **DALL-E**: Developed by OpenAI, it generates diverse and high-quality images from text prompts. It uses a transformer-based architecture.
- **VQ-VAE (Vector Quantized Variational Autoencoder)**: Used to encode images into discrete latent spaces, facilitating the generation of novel images from text.

### How They Work

1. **Text Encoding**: The input text is processed to capture semantic meanings using natural language processing techniques.

2. **Image Generation**: The encoded text is fed into a generative model, often using techniques like GANs (Generative Adversarial Networks) or VAEs (Variational Autoencoders), to create an image that matches the description.

3. **Training Process**:
   - Models are trained on large datasets of paired images and text.
   - Through iterative learning, they understand the association between textual cues and visual content.

#### Key Points

- Text-to-image models rely on diffusion models, transformers, and GANs.
- They align text embeddings with visual representations to generate realistic images.
- Challenges include biases, alignment issues, and resolution limits.
- Notable applications include DALL·E and similar systems for creative and practical uses.

## 4. The computational model for Foraging Ants and the details of its workings.

The computational model for foraging ants demonstrates how simple rules followed by individual ants can lead to complex, intelligent group behavior. This model simulates how ants explore their environment to find food, using pheromone trails to communicate effectively within a colony. Each ant wanders the grid, marks pheromone trails while foraging, and follows existing trails probabilistically, which promotes efficient food gathering by the entire colony.

Ant Colony Optimization (ACO) algorithms, stemming from this model, are pivotal in solving complex optimization problems by mimicking these behavioral patterns. They apply to various domains like network routing and resource scheduling, showcasing how natural phenomena inspire robust, scalable computing techniques that emulate environmental intelligence and adaptability.

### Types of Pheromones and Ant Behavior

The model employs two types of pheromones:

1. **Search Pheromones ($\alpha$)**:

   - Released when ants are exploring for food.
   - Ants follow the gradient of these pheromones when returning home, enhancing path discovery.

2. **Food Pheromones ($\beta$)**:
   - Emitted when ants are carrying food back to the nest.
   - Used by other ants to follow the most efficient route back to the food source.

### Ant Behavior Stages

1. **Searching for Food**:

   - Ants move randomly, depositing $\alpha$ pheromones.
   - They choose directions based on local pheromone concentrations, leading them to potential food sources.

2. **Finding and Carrying Food**:

   - Upon finding food, ants switch to depositing $\beta$ pheromones.
   - Return to the nest by following the strongest $\alpha$ gradients, reinforcing efficient trails.

3. **Trail Reinforcement and Optimization**:
   - Successful routes are reinforced as more ants follow them, enhancing the concentration of $\beta$ pheromones.
   - Trails that are not reinforced naturally dissipate due to evaporation, optimizing the network of paths over time.

### Model Explanation

In this model, ants make decisions based on the intensity of pheromone trails. Each direction an ant can take is associated with pheromone levels, influencing the likelihood of that path being chosen. The probability of choosing a particular direction is proportional to the pheromone concentration in that direction relative to others.

To calculate the probability of choosing a direction, the pheromone levels in all directions are considered.

#### Example

To calculate the probability of choosing the "STRAIGHT_AHEAD" direction, consider the pheromone levels in all directions:

- LEFT: 20
- STRAIGHT_AHEAD: 20
- RIGHT: 60

The formula for the probability $P$ of choosing a direction is:

$$
P(\text{direction}) = \frac{\text{pheromone in chosen direction}}{\text{total pheromone in all directions}}
$$

For STRAIGHT_AHEAD, this becomes:

$$
P(\text{STRAIGHT\_AHEAD}) = \frac{20}{20 + 20 + 60} = \frac{20}{100} = 0.2
$$

Thus, the probability of the agent choosing the STRAIGHT_AHEAD direction is $0.2$, or $20\%$.

### Key Points

- **Pheromone Influence**: Ant decisions are based on pheromone levels, with higher concentrations increasing the probability of a chosen path.
- **Probabilistic Behavior**: Directions are selected based on pheromone ratios relative to all possible paths.
- **Emergent Behavior**: Collective foraging efficiency emerges from individual decision-making rules.

## 5. The Schelling model and it’s working on examples.

The Schelling model of segregation evaluates how individual preferences can lead to large-scale social patterns, such as community segregation. Agents on a grid prefer neighbors of similar identity; over time, even slight preferences can lead to pronounced segregation. This model sheds light on unintended consequences of individual decisions and offers powerful insights into social dynamics and policy implications.

Applications of the Schelling model extend beyond urban planning to areas like economic segregation, resource allocation, and collective behavior studies. It emphasizes that even minimal individual biases can catalyze significant structural changes, thereby informing efforts to enhance social integration and mitigate segregation through deliberate policy design and interventions.

### Model application example

Using Schelling model, given that agents are either of type RED or BLUE and are placed on a grid. Each agent has a tolerance level, representing the percentage of neighboring agents of the same type that makes it comfortable. If the proportion of like neighbors falls below this tolerance, the agent becomes unhappy and moves to a new location where its preference is satisfied.

### Scenario Analysis

Given the exam question:

- **Agent A** is RED.
- The neighborhood consists of the following configuration:

  | RED  | BLUE    | RED  |
  | ---- | ------- | ---- |
  | BLUE | Agent A | BLUE |
  | RED  | BLUE    | RED  |

- **Tolerance Level**: 55%

#### Calculation for Agent A's Decision

Agent A assesses its satisfaction based on its immediate neighbors. It counts the RED and BLUE agents among its 8 surrounding positions:

- RED neighbors: 4 (excluding Agent A)
- BLUE neighbors: 4

Agent A calculates the percentage of RED neighbors:

$$
\text{Percentage of like neighbors} = \frac{\text{Number of RED neighbors}}{\text{Total neighbors}} = \frac{4}{8} = 0.5 = 50\%
$$

Since 37.5% is less than the tolerance level of 55%, Agent A is unhappy.

### Action Taken by Agent A

Given that Agent A's like neighbor percentage (37.5%) is below its tolerance level (55%), Agent A will choose to move to a different location. It will search for a new spot where the proportion of like neighbors equals or exceeds 55%, aligning with its tolerance requirement.

### Key Points

- **Tolerance Level**: Determines an agent's satisfaction with its neighborhood composition.
- **Segregation Emergence**: Even minor preferences for similar neighbors can lead to large-scale segregation.
- **Local Decision Impact**: Individual decisions, based on local environments, drive macro-level patterns.

In this model, understanding individual preferences and local dynamics is essential for predicting broader societal structures.

## 6. Basic ethical frameworks for technology.

Ethical frameworks for technology aim to guide the responsible development and integration of AI systems by emphasizing fairness, accountability, and transparency. These frameworks address concerns about bias, privacy, data security, and the potential societal implications of deploying AI technologies. They advocate for practices that prevent discrimination, protect user data, and align AI functionality with human values.

Frameworks such as "privacy by design" and "human-centered AI" encourage proactive measures throughout the design and deployment of AI systems. By integrating such frameworks, developers and policymakers can ensure technologies not only advance innovation but also contribute positively to society, minimizing risks while enhancing trust and accountability in technological applications.

### Three rules of technology

1. When you invent a new technology, you uncover a new class of responsibilities
2. If the tech confers power, it starts a race
3. If you do not coordinate, the race ends in tragedy

### Ethical Frameworks Overview

1. **Fairness and Non-Discrimination**:

   - Emphasizes developing AI systems that treat all users equitably.
   - Mitigates biases in data and algorithms, preventing unfair treatment.

2. **Transparency and Explainability**:

   - Advocates clarity in how technologies make decisions.
   - Encourages models that provide explanations for actions and predictions.

3. **Privacy by Design**:

   - Integrates privacy-preserving measures into system architecture from the outset.
   - Ensures personal data protection and secure handling of sensitive information.

4. **Human-Centered AI**:

   - Focuses on creating AI systems that prioritize human values and needs.
   - Encourages user-friendly designs that enhance interaction and usability.

5. **Accountability and Responsibility**:
   - Stresses assigning responsibility for AI actions to prevent misuse.
   - Promotes robust documentation and monitoring for system outputs.

### Importance of Ethical Considerations

- **Societal Impact**: Ethical frameworks evaluate the broader implications of technology deployment, ensuring it adds value without causing harm.
- **Building Trust**: Adhering to ethical guidelines fosters user trust and acceptance, essential for successful technology adoption.
- **Legal Compliance**: Ensures alignment with regulatory standards, minimizing legal risks and promoting good practices.

### Key Points

- **Promoting Fairness**: Design AI to eliminate biases that could lead to discrimination.
- **Ensuring Transparency**: Users should understand decision-making processes to enhance trust.
- **Prioritizing Privacy**: Implement privacy-preserving measures throughout development.
- **Human-Centered Design**: Focus on AI meeting human needs and enhancing user interaction.
- **Fostering Accountability**: Establish clear responsibility chains for managing AI actions.

These ethical frameworks guide the development of technology that positively influences and integrates into society.
